{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x61vVpuUX4jJ"
      },
      "outputs": [],
      "source": [
        "def PreProcessing(dat):\n",
        "  VerbalConv = []\n",
        "  with open('VerbalConversion.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "      VerbalConv.append(row)\n",
        "  QuantConv = []\n",
        "  with open('QuantConversion.csv') as csv_file:\n",
        "    csv_reader2 = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader2:\n",
        "      QuantConv.append(row)\n",
        "  dat=dat[dat[5] == 'Accepted']\n",
        "  dat=dat[dat[3] == 'MS']\n",
        "  dat=dat.drop([0, 2, 3, 4, 5, 6, 7, 8, 13, 14, 15, 16, 17, 18], axis=1)\n",
        "  dat=dat.dropna(axis=0, how='any')\n",
        "  dat=dat.reset_index(drop=True)\n",
        "  dat.loc[dat[9] > 4.0, 9]=dat.loc[dat[9] > 4.0, 9]*4/10\n",
        "  for i, j in VerbalConv:\n",
        "    dat[10]=dat[10].mask(dat[10] == int(i), int(j))\n",
        "  for i, j in QuantConv:\n",
        "    dat[11]=dat[11].mask(dat[11] == int(i), int(j))\n",
        "  dat[9]=pd.to_numeric(dat[9])\n",
        "  dat[10]=pd.to_numeric(dat[10])\n",
        "  dat[11]=pd.to_numeric(dat[11])\n",
        "  dat[12]=pd.to_numeric(dat[12])\n",
        "  dat=pd.DataFrame(dat.values, columns=[\"College Name\", \"GPA\",\"Verbal\",\"Quants\",\"Writing\"])\n",
        "  dat.to_csv(\"cleanedDataFinal.csv\")\n",
        "  print('Preprocessing Done')\n",
        "  return dat\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ProcessedDat = PreProcessing(dat)\n",
        "ProcessedDat.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "09CBYtegaTjY",
        "outputId": "a9a78470-ecd7-4ead-ce1d-0bc968ebb3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e4366beba826>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mProcessedDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mProcessedDat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of the data"
      ],
      "metadata": {
        "id": "waY0pOrIdpvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clustering():\n",
        "  dat = pd.read_csv(\"cleanedDataFinal.csv\")\n",
        "  dat = dat.drop(['Unnamed: 0'], axis=1)\n",
        "  UniqueCollegeData = dat.groupby(\"College Name\", as_index=False).mean()\n",
        "  clusterData = UniqueCollegeData.drop([\"College Name\"], axis=1)\n",
        "  no_of_clusters = 5\n",
        "  model = KMeans(n_clusters=no_of_clusters, init='k-means++', max_iter=100, n_init=1)\n",
        "  model.fit(clusterData)\n",
        "  s_score = silhouette_score(clusterData, model.labels_)\n",
        "  UniqueCollegeDatal['Cluster']= pd.Series(model.labels_)\n",
        "  print(\"Clustering Done\")\n",
        "  print('Silhouette Score for Clustering is '+str(s_score))\n",
        "  return UniqueCollegeData\n"
      ],
      "metadata": {
        "id": "F4c-_6mZaTqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusteredData = clustering()\n",
        "clusteredData.head()"
      ],
      "metadata": {
        "id": "QeuBIg1denes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering and Alloting Tiers"
      ],
      "metadata": {
        "id": "ICw24kzGevzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelCreation(datPoints):\n",
        "  CollegeTiers = []\n",
        "  with open('CollegeTiers.csv') as csv_file:\n",
        "    csv_reader2 = csv.reader(csv_file, delimiter=', ')\n",
        "    for row in csv_reader2:\n",
        "      CollegeTiers.append(row[1:])\n",
        "  datPoints\n",
        "  datPoints[\"Tier\"] = \"\"\n",
        "  for i, j in CollegeTiers:\n",
        "    datPoints[\"Tier\"] = datPoints[\"Tier\"].mask(datPoints[\"College Name\"] == i, j)\n",
        "  datPoints = datPoints.drop(['College Name'], axis=1)\n",
        "  X = np.asarray(datPoints.drop(['Tier'], axis=1).values)\n",
        "  y= np.asarray (datPoints['Tier'].values)\n",
        "  X_train, X_test, Y_ train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  model= MLPClassifier(alpha=le-4, hidden_layer_sizes=(9, 7), random_state=1, solver='bfgs', max_iter=10000)\n",
        "  model.fit(X_train, Y_train)\n",
        "  # model. fit (X, y)\n",
        "  filename= \"CollegeProbPredictor.sav\"\n",
        "  pickle.dump(model,open(filename,'wb'))\n"
      ],
      "metadata": {
        "id": "jtRoVEBFe0BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ModelCreation_predict(datPoints):\n",
        "  CollegeTiers = []\n",
        "  with open('CollegeTiers.csv') as csv_file:\n",
        "    csv_reader2 = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_reader2:\n",
        "      CollegeTiers.append(row[1:])\n",
        "  datPoints\n",
        "  datPoints[\"Tier\"] = \"\"\n",
        "\n",
        "  # print (datPoints.shape)\n",
        "  for i, j in CollegeTiers:\n",
        "    datPoints[\"Tier\"] = datPoints[\"Tier\"].mask(datPoints[\"'College Name\"] == i, j)\n",
        "  datPoints = datPoints.drop(['College Name'], axis=1)\n",
        "\n",
        "  # print (datPoints.shape)\n",
        "  X= np.asarray(datPoints.drop(['Tier'], axis=1).values)\n",
        "  y = np.asarray(datPoints['Tier'].values)\n",
        "\n",
        "  # print (X. shape)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  return X_test, Y_test\n"
      ],
      "metadata": {
        "id": "i-Sb8HnofTy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP Model Creation and Training of Dataset"
      ],
      "metadata": {
        "id": "p_SyryGpgnBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test = ModelCreation_predict(ProcessedDat)\n",
        "MLPmodel = pickle.load(open('CollegeProbPredictor.sav', 'rb'))\n",
        "Y_pred = MLPmodel.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "CollegeTiers = []\n",
        "with open('CollegeTiers.csv') as csc_file:\n",
        "  csv_reader2 = csv.reader(csv_file, delimiter=',')\n",
        "  for row in csv_reader2:\n",
        "    CollegeTiers.append(row[1:])\n",
        "\n",
        "datPoints=pd.read_csv(\"clusteredDatawithTiers.csv\")\n",
        "datPoints=datPoints.drop(['Cluster', 'Unnamed: 0'], axis=1)\n",
        "datPoints.head()\n"
      ],
      "metadata": {
        "id": "ucQlpi3xgr1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing of Trained Data (incomplete)"
      ],
      "metadata": {
        "id": "h1FCUjKvhlq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictListCollege(Scores, model):\n",
        "  Scores = np.asarray(Scores).reshape(1, -1)\n",
        "  ProbMax = max(max(model.predict_proba(Scores)))\n",
        "  tier = model.predict(Scores)[0]\n",
        "  CollegeTierList = {}\n",
        "  if (tier == '5'):\n",
        "    nTier = 10\n",
        "    Neigh1 = NearestNeighbors(n_ neighbors=nTier, p=2, algorithm='auto', metric='euclidean')\n",
        "    TierUpperPoints = datPoints[datPoints[\"Tier\"] == int(tier)].reset_index(drop=True)\n",
        "    Neigh1.fit(np.asarray(TierUpperPoints.drop(['College Name', 'Tier'], axis=1).values))\n",
        "    Indexes = Neighl.kneighbors(Scores, return_distance=False)[0]\n",
        "    CollegeList = [TierUpperPoints.at[i, 'College Name'] for i in Indexes]\n",
        "    UTier = []\n",
        "    for Name in CollegeList:\n",
        "      NeededVerbal = datPoints[datPoints [\"College Name\"] == Name][\"Verbal\"].values[0]\n",
        "      NeededQuants= datPoints[datPoints [\"College Name\"] == Name][\"Quants\"].values[0]\n",
        "      NeededGPA= datPoints[datPoints [\"College Name\"] == Name][\"GPA\"].values[0]\n",
        "      NeededWriting = datPoints[datPoints [\"College Name\"] == Name][\"Writing\"].values[0]\n",
        "      UTier.append([Name, NeededVerbal, NeededQuants, NeededGPA, NeededWriting])\n",
        "    CollegeTierList['UpperTier'] = UTier\n",
        "    CollegeTierList['LowerTier'] = []\n",
        "  else:\n",
        "    nTier = int(math.ceil(ProbMax*10))\n",
        "    nTierLower = int(10-nTier)\n",
        "    Neigh1 = NearestNeighbors(n_neighbors=nTier, p=2, algorithm= 'auto', metric='euclidean')\n",
        "    TierUpperPoints = datPoints[datPoints[\"Tier\"] == int(tier)].reset_index(drop=True)\n",
        "    Neighl.fit(np.asarray(TierUpperPoints.drop(['College Name', 'Tier'], axis=1).values))\n",
        "    Indexes = Neighl.kneighbors(Scores, return_distance=False) [0]\n",
        "    CollegeList = [TierUpperPoints.at[i,'College Name'] for i in Indexes]\n",
        "    UTier = []\n",
        "    for Name in CollegeList:\n",
        "      NeededVerbal = datPoints[datPoints[\"College Name\"] == Name][\"'Verbal\"].values[0]\n",
        "      NeededQuants = datPoints[datPoints[\"College Name\"] == Name][\"Quants\"].values[0]\n",
        "      NeededGPA = datPoints[datPoints[\"College Name\"] == Name] [\"GPA\"]values[0]\n",
        "      Neededwriting = datPoints[datPoints[\"College Name\"] == Name][\"Writing\"].values[0]\n",
        "      UTier.append([Name, NeededVerbal, NeededQuants, NeededGPA, NeededWriting])\n",
        "    Neigh2 = NearestNeighbors(n_neighbors=nTierLower, p=2, algorithm='auto', metric=' euclidean')\n",
        "    TierLowerPoints = datPoints[datPoints[\"Tier\"] == (int(tier)+1)].reset_index(drop = True)\n",
        "    Neigh2.fit(np.asarray(TierLowerPoints.drop(['College Name', 'Tier'], axis=1).values))\n",
        "    TierLowerPoints.head()\n",
        "    Indexs2 = Neigh2.kneighbors(Scores, return_distance=False)[0]\n",
        "    CollegeList2 = [TierLowerPoints.at[i, 'College Name'] for i in Indexs2]\n",
        "    LTier = []\n",
        "    for Name in CollegeList2:\n",
        "      NeededVerbal = datPoints[datPoints[\"College Name\"] == Name][\"Verbal\"].values[0]\n",
        "      NeededQuants = datPoints[datPoints[\"College Name\"] == Name][\"Quants\"].values[0]\n",
        "      NeededGPA = datPoints[datPoints[\"College Name\"] == Name][\"GPA\"].values[0]\n",
        "      NeededWriting= datPoints[datPoints[\"College Name\"] == Name][\"Writing\"].values[0]\n",
        "      LTier.append([Name, NeededVerbal, NeededQuants, NeededGPA, NeededWriting])\n",
        "    ColleqeTierList['UpperTier'] = UTier\n"
      ],
      "metadata": {
        "id": "RqaTrKdMhoaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply K-NN for calulating nearest neighbors in prediction list"
      ],
      "metadata": {
        "id": "amhXuBAZ0dCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CollegeList = predictListCollege([3.52,160,166,3.5]),MLPmodel)\n",
        "#[GPA, VERBAL, QUANTS, WRITING]\n",
        "for k in CollegeList.keys():\n",
        "  print(k+\":\\n\\n\")\n",
        "  for college in CollegeList[k]:\n",
        "    print(college[0]+\"\\nRequired Verbal Score: \"+str(college[1])+\" Required Quants Score: \"+str(college[2])\n",
        "    +\" Required GPA: \"+str(college[3])+\" Required Writing Score: \"+str(college[4])+\"\\n\")"
      ],
      "metadata": {
        "id": "XqNYZWBt0iDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}